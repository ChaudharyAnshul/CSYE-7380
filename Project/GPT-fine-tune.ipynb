{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d31747c-2e14-4c9b-8752-7572531174f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaudhary.ans/.conda/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-11 06:33:37.118217: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-11 06:33:37.131507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733916817.153360   12328 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733916817.160028   12328 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 06:33:37.184783: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a26d8bb7-32fd-4e83-a616-83a1b220a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/reminiscences_of_a_stock_operator_qa.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f4ceab-9a47-4b0e-9cdf-ebb15bd9d573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What was your first job in finance?</td>\n",
       "      <td>My first job was as a quotation-board boy at a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What key lessons did you learn from your first...</td>\n",
       "      <td>I learned the importance of quick mental calcu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How did your early skills in math affect your ...</td>\n",
       "      <td>My strong math skills, especially mental arith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Describe your first experience making money in...</td>\n",
       "      <td>My first profitable trade was on Burlington.  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What was your initial trading strategy?</td>\n",
       "      <td>My initial strategy focused on recognizing pat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0                What was your first job in finance?   \n",
       "1  What key lessons did you learn from your first...   \n",
       "2  How did your early skills in math affect your ...   \n",
       "3  Describe your first experience making money in...   \n",
       "4            What was your initial trading strategy?   \n",
       "\n",
       "                                              answer  \n",
       "0  My first job was as a quotation-board boy at a...  \n",
       "1  I learned the importance of quick mental calcu...  \n",
       "2  My strong math skills, especially mental arith...  \n",
       "3  My first profitable trade was on Burlington.  ...  \n",
       "4  My initial strategy focused on recognizing pat...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13413822-61c8-4475-82b9-ae036eb08d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0526ddac-576b-4490-9a23-c563ed52d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length):\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # Set the pad_token to eos_token if not already set\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.iloc[index]\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        \n",
    "        # Prepare the input for GPT-2\n",
    "        input_text = f\"Question: {question}\\nAnswer:\"\n",
    "        target_text = answer\n",
    "        \n",
    "        # Tokenize the input and the target (GPT-2 is a causal language model)\n",
    "        encoding = self.tokenizer(\n",
    "            input_text,\n",
    "            target_text,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",  # Enable padding here\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoding['input_ids'].squeeze(0),\n",
    "            \"attention_mask\": encoding['attention_mask'].squeeze(0),\n",
    "            \"labels\": encoding['input_ids'].squeeze(0)  # GPT-2 uses causal language modeling\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ff9f50-a163-404c-84bf-1d82c187913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db9450b-a094-4c0d-9413-e41385a1c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 2e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5c30c4-e225-4dd6-bed5-a0aa2fd55c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = QADataset(train_df, tokenizer, MAX_LEN)\n",
    "test_dataset = QADataset(test_df, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ebdf7d0-5b77-4362-b4c1-83acaa5889c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afa1ac1c-40f6-4879-88fc-1cf2a05c6090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d131d404-8b90-4bd1-8cbe-03246dae9d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaudhary.ans/.conda/envs/myenv/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff90a37-c4fb-4801-a2fc-0c5ea7989320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eb7940a-d75d-475c-a7f1-3a3750b529bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06363214-0f93-45bb-9623-24977940cd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:17<00:00,  1.53it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4724, Validation Loss: 1.0485\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0392, Validation Loss: 0.9554\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9262, Validation Loss: 0.9101\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.65it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8451, Validation Loss: 0.8808\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7770, Validation Loss: 0.8623\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7257, Validation Loss: 0.8477\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6775, Validation Loss: 0.8439\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.65it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6323, Validation Loss: 0.8423\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.64it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5869, Validation Loss: 0.8453\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:12<00:00,  1.63it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5473, Validation Loss: 0.8483\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:16<00:00,  1.55it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5112, Validation Loss: 0.8560\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:16<00:00,  1.56it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:17<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4774, Validation Loss: 0.8642\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [04:04<00:00,  2.06s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:16<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4432, Validation Loss: 0.8848\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [02:34<00:00,  1.30s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:05<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4167, Validation Loss: 0.8906\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [03:36<00:00,  1.82s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:17<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3867, Validation Loss: 0.9097\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [07:38<00:00,  3.86s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:29<00:00,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3616, Validation Loss: 0.9124\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [09:21<00:00,  4.72s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:31<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3338, Validation Loss: 0.9476\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [08:49<00:00,  4.45s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:30<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3153, Validation Loss: 0.9515\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [09:04<00:00,  4.58s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2939, Validation Loss: 0.9688\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [09:22<00:00,  4.73s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:36<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2727, Validation Loss: 0.9858\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [09:22<00:00,  4.72s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:35<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2607, Validation Loss: 0.9976\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [08:10<00:00,  4.12s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:33<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2454, Validation Loss: 1.0096\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [08:50<00:00,  4.46s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2264, Validation Loss: 1.0241\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [08:44<00:00,  4.41s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:36<00:00,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2162, Validation Loss: 1.0233\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [08:31<00:00,  4.30s/it]\n",
      "Evaluating: 100%|██████████| 30/30 [00:29<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2083, Validation Loss: 1.0336\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:47<00:00,  1.11it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1958, Validation Loss: 1.0593\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:15<00:00,  1.58it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1894, Validation Loss: 1.0515\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1784, Validation Loss: 1.0654\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1739, Validation Loss: 1.0732\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1632, Validation Loss: 1.0918\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1558, Validation Loss: 1.0911\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1542, Validation Loss: 1.0946\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1479, Validation Loss: 1.1152\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1426, Validation Loss: 1.1120\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1371, Validation Loss: 1.1336\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1333, Validation Loss: 1.1353\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:15<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1294, Validation Loss: 1.1432\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1249, Validation Loss: 1.1460\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1227, Validation Loss: 1.1475\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.59it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1195, Validation Loss: 1.1508\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1148, Validation Loss: 1.1657\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1141, Validation Loss: 1.1638\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1107, Validation Loss: 1.1816\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1077, Validation Loss: 1.1816\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1073, Validation Loss: 1.1982\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1034, Validation Loss: 1.2077\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:13<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1012, Validation Loss: 1.1951\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.61it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1020, Validation Loss: 1.2127\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:04<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0989, Validation Loss: 1.2086\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 119/119 [01:14<00:00,  1.60it/s]\n",
      "Evaluating: 100%|██████████| 30/30 [00:05<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0973, Validation Loss: 1.2172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    train_loss = train(model, train_loader, optimizer, DEVICE)\n",
    "    val_loss = evaluate(model, test_loader, DEVICE)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f331cf8-f1bb-46e5-8b11-638c8929de05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fine-tuned and saved!\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"./gpt2-chatbot\")\n",
    "tokenizer.save_pretrained(\"./gpt2-chatbot\")\n",
    "\n",
    "print(\"Model fine-tuned and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "784cb5c9-9e55-4d61-b688-53f707fed67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_gpt2(model, tokenizer, question, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare the input prompt for the model\n",
    "    input_text = f\"Question: {question}\\nAnswer:\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate the answer\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"], \n",
    "            max_length=128,  # You can adjust this to control the length of the answer\n",
    "            num_beams=5,     # Beam search for better quality\n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "    # Decode and return the answer\n",
    "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff161450-f19a-4b71-8266-16e2523fabbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Question: What is the main theme of the book?\n",
      "Answer:The primary theme is greed and fear, the need to avoid overtrading and impulsive decision-making, and the need to maintain discipline and composure in the face of market manipulation.  It's about understanding the combination of greed and fear with rational analysis and decisive action.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"What is the main theme of the book?\"\n",
    "answer = chat_with_gpt2(model, tokenizer, question, device=DEVICE)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd9b8253-2d0a-4d1a-86db-b45ae1541915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Question: What is the correct time to enter the market?\n",
      "Answer:The correct time to enter the market is when you have a good understanding of market trends and a good understanding of the fundamental reasons behind price movements.  You must also be prepared to make rational, well-timed trades to capitalize on the market's movements.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"What is the correct time to enter the market?\"\n",
    "answer = chat_with_gpt2(model, tokenizer, question, device=DEVICE)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea9316ae-cf46-484d-a69d-8bb925e45edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Question: What was your first job in finance?\n",
      "Answer:My first job was as a quotation-board boy at a stock brokerage firm. I was quick with numbers and excelled at mental arithmetic, skills that proved invaluable later in my career.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "question = \"What was your first job in finance?\"\n",
    "answer = chat_with_gpt2(model, tokenizer, question, device=DEVICE)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d881e5-8531-4f54-be69-429cdc3ca2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
