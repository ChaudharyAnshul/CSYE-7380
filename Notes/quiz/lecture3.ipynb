{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq=[{\"question\": \"What is the primary purpose of layers in a neural network?\", \"opt1\": \"To add complexity to the model\", \"opt2\": \"To organize and process data\", \"opt3\": \"To increase computational speed\", \"opt4\": \"To reduce the number of parameters\"}, {\"question\": \"What is the function of the input layer in a neural network?\", \"opt1\": \"To perform complex computations\", \"opt2\": \"To receive raw input data\", \"opt3\": \"To produce the final output\", \"opt4\": \"To apply activation functions\"}, {\"question\": \"What is the purpose of hidden layers in a neural network?\", \"opt1\": \"To directly connect input and output layers\", \"opt2\": \"To add non-linearity to the network\", \"opt3\": \"To perform transformations on the input data\", \"opt4\": \"To reduce the dimensionality of the data\"}, {\"question\": \"What is the function of the output layer in a neural network?\", \"opt1\": \"To receive raw input data\", \"opt2\": \"To perform complex computations\", \"opt3\": \"To produce the network's predictions\", \"opt4\": \"To apply activation functions\"}, {\"question\": \"What are activation functions in neural networks?\", \"opt1\": \"Methods for training neural networks\", \"opt2\": \"Mathematical functions applied to node inputs\", \"opt3\": \"Types of neural network architectures\", \"opt4\": \"Methods for data preprocessing\"}, {\"question\": \"What is the main purpose of backpropagation in neural networks?\", \"opt1\": \"To initialize network weights\", \"opt2\": \"To adjust network weights during training\", \"opt3\": \"To select appropriate activation functions\", \"opt4\": \"To preprocess input data\"}, {\"question\": \"What is gradient descent in the context of neural network training?\", \"opt1\": \"A method for selecting activation functions\", \"opt2\": \"An activation function itself\", \"opt3\": \"A method for initializing network weights\", \"opt4\": \"An iterative optimization algorithm that minimizes the loss function\"}, {\"question\": \"What is the key difference between a shallow neural network and a deep neural network?\", \"opt1\": \"Shallow networks use fewer activation functions\", \"opt2\": \"Deep networks are trained using different algorithms\", \"opt3\": \"Deep networks use multiple hidden layers\", \"opt4\": \"Shallow networks are more computationally efficient\"}, {\"question\": \"What is the term 'deep' in 'deep learning' referring to?\", \"opt1\": \"The complexity of the algorithms used\", \"opt2\": \"The amount of training data required\", \"opt3\": \"The depth (number of hidden layers) in a neural network\", \"opt4\": \"The high computational cost of training\"}, {\"question\": \"What is the process of training deep neural networks often called?\", \"opt1\": \"Gradient descent\", \"opt2\": \"Backpropagation\", \"opt3\": \"Deep learning\", \"opt4\": \"Activation function\"}, {\"question\": \"What problem do the vanishing and exploding gradient problems primarily affect?\", \"opt1\": \"Shallow neural networks\", \"opt2\": \"Recurrent neural networks\", \"opt3\": \"Convolutional neural networks\", \"opt4\": \"All types of neural networks equally\"}, {\"question\": \"What are GRUs (Gated Recurrent Units) and LSTMs (Long Short-Term Memory units)?\", \"opt1\": \"Types of activation functions\", \"opt2\": \"Types of regularization techniques\", \"opt3\": \"Specialized RNN architectures designed to address vanishing/exploding gradients\", \"opt4\": \"Types of optimization algorithms\"}, {\"question\": \"What is a significant advantage of using LSTMs over traditional RNNs?\", \"opt1\": \"LSTMs are computationally more efficient\", \"opt2\": \"LSTMs are simpler to implement\", \"opt3\": \"LSTMs have better memory capabilities for long-range dependencies\", \"opt4\": \"LSTMs are less prone to overfitting\"}, {\"question\": \"What is a primary way that LSTMs and GRUs mitigate the vanishing gradient problem?\", \"opt1\": \"By using a different activation function\", \"opt2\": \"By employing gated mechanisms to control the flow of information\", \"opt3\": \"By introducing non-linearity in the model\", \"opt4\": \"By reducing the number of parameters\"}, {\"question\": \"Which of the following is NOT a typical application of LSTMs?\", \"opt1\": \"Machine translation\", \"opt2\": \"Image classification\", \"opt3\": \"Speech recognition\", \"opt4\": \"Time series forecasting\"}, {\"question\": \"What are the main states that are transferred from one LSTM block to the next?\", \"opt1\": \"Input and output states\", \"opt2\": \"Hidden state and cell state\", \"opt3\": \"Query and key states\", \"opt4\": \"Weights and biases\"}]\n",
    "answers=[{\"question\": \"What is the primary purpose of layers in a neural network?\", \"answer\": \"To organize and process data\", \"explanation\": \"Layers in a neural network are the building blocks that organize and process data sequentially.\"}, {\"question\": \"What is the function of the input layer in a neural network?\", \"answer\": \"To receive raw input data\", \"explanation\": \"The input layer is the first layer and is responsible for receiving and representing the raw input data.\"}, {\"question\": \"What is the purpose of hidden layers in a neural network?\", \"answer\": \"To perform transformations on the input data\", \"explanation\": \"Hidden layers perform various transformations on the input data through weighted connections between nodes.\"}, {\"question\": \"What is the function of the output layer in a neural network?\", \"answer\": \"To produce the network's predictions\", \"explanation\": \"The output layer is the final layer that produces the network's predictions or outputs.\"}, {\"question\": \"What are activation functions in neural networks?\", \"answer\": \"Mathematical functions applied to node inputs\", \"explanation\": \"Activation functions introduce non-linearity into the network's processing and determine node activation.\"}, {\"question\": \"What is the main purpose of backpropagation in neural networks?\", \"answer\": \"To adjust network weights during training\", \"explanation\": \"Backpropagation is an algorithm that calculates gradients and adjusts network weights to minimize errors.\"}, {\"question\": \"What is gradient descent in the context of neural network training?\", \"answer\": \"An iterative optimization algorithm that minimizes the loss function\", \"explanation\": \"Gradient descent is an iterative optimization algorithm used to find model parameters that minimize the loss function.\"}, {\"question\": \"What is the key difference between a shallow neural network and a deep neural network?\", \"answer\": \"Deep networks use multiple hidden layers\", \"explanation\": \"Deep neural networks have multiple hidden layers, while shallow networks have only one or two.\"}, {\"question\": \"What does the term 'deep' refer to in 'deep learning'?\", \"answer\": \"The depth (number of hidden layers) in a neural network\", \"explanation\": \"'Deep' refers to the number of hidden layers in a neural network, which usually correlates with the complexity of patterns the network can learn.\"}, {\"question\": \"What is the process of training deep neural networks often called?\", \"answer\": \"Deep learning\", \"explanation\": \"The process of training deep neural networks is known as deep learning.\"}, {\"question\": \"What problem do the vanishing and exploding gradient problems primarily affect?\", \"answer\": \"Recurrent neural networks\", \"explanation\": \"The vanishing and exploding gradient problems are particularly prominent in RNNs due to their recurrent nature.\"}, {\"question\": \"What are GRUs (Gated Recurrent Units) and LSTMs (Long Short-Term Memory units)?\", \"answer\": \"Specialized RNN architectures designed to address vanishing/exploding gradients\", \"explanation\": \"GRUs and LSTMs are specialized RNN architectures designed to improve the ability to learn long-range dependencies in sequential data.\"}, {\"question\": \"What is a significant advantage of using LSTMs over traditional RNNs?\", \"answer\": \"LSTMs have better memory capabilities for long-range dependencies\", \"explanation\": \"LSTMs utilize sophisticated mechanisms like gates to better manage information flow, leading to enhanced handling of long-range dependencies compared to traditional RNNs.\"}, {\"question\": \"What is a primary way that LSTMs and GRUs mitigate the vanishing gradient problem?\", \"answer\": \"By employing gated mechanisms to control the flow of information\", \"explanation\": \"The gates (input, output, forget) in LSTMs and GRUs carefully control the flow of information through the network, preventing gradients from vanishing or exploding during backpropagation.\"}, {\"question\": \"Which of the following is NOT a typical application of LSTMs?\", \"answer\": \"Image classification\", \"explanation\": \"While RNNs can be used for image processing tasks, LSTMs are more commonly applied to sequential data processing problems.\"}, {\"question\": \"What are the main states that are transferred from one LSTM block to the next?\", \"answer\": \"Hidden state and cell state\", \"explanation\": \"The hidden state and cell state are the two key internal states that are updated and passed along within an LSTM network.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mcq), len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary purpose of layers in a neural network?',\n",
       " 'opt1': 'To add complexity to the model',\n",
       " 'opt2': 'To organize and process data',\n",
       " 'opt3': 'To increase computational speed',\n",
       " 'opt4': 'To reduce the number of parameters'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary purpose of layers in a neural network?',\n",
       " 'answer': 'To organize and process data',\n",
       " 'explanation': 'Layers in a neural network are the building blocks that organize and process data sequentially.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the function of the input layer in a neural network?',\n",
       " 'opt1': 'To perform complex computations',\n",
       " 'opt2': 'To receive raw input data',\n",
       " 'opt3': 'To produce the final output',\n",
       " 'opt4': 'To apply activation functions'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the function of the input layer in a neural network?',\n",
       " 'answer': 'To receive raw input data',\n",
       " 'explanation': 'The input layer is the first layer and is responsible for receiving and representing the raw input data.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of hidden layers in a neural network?',\n",
       " 'opt1': 'To directly connect input and output layers',\n",
       " 'opt2': 'To add non-linearity to the network',\n",
       " 'opt3': 'To perform transformations on the input data',\n",
       " 'opt4': 'To reduce the dimensionality of the data'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of hidden layers in a neural network?',\n",
       " 'answer': 'To perform transformations on the input data',\n",
       " 'explanation': 'Hidden layers perform various transformations on the input data through weighted connections between nodes.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the function of the output layer in a neural network?',\n",
       " 'opt1': 'To receive raw input data',\n",
       " 'opt2': 'To perform complex computations',\n",
       " 'opt3': \"To produce the network's predictions\",\n",
       " 'opt4': 'To apply activation functions'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the function of the output layer in a neural network?',\n",
       " 'answer': \"To produce the network's predictions\",\n",
       " 'explanation': \"The output layer is the final layer that produces the network's predictions or outputs.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are activation functions in neural networks?',\n",
       " 'opt1': 'Methods for training neural networks',\n",
       " 'opt2': 'Mathematical functions applied to node inputs',\n",
       " 'opt3': 'Types of neural network architectures',\n",
       " 'opt4': 'Methods for data preprocessing'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are activation functions in neural networks?',\n",
       " 'answer': 'Mathematical functions applied to node inputs',\n",
       " 'explanation': \"Activation functions introduce non-linearity into the network's processing and determine node activation.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the main purpose of backpropagation in neural networks?',\n",
       " 'opt1': 'To initialize network weights',\n",
       " 'opt2': 'To adjust network weights during training',\n",
       " 'opt3': 'To select appropriate activation functions',\n",
       " 'opt4': 'To preprocess input data'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the main purpose of backpropagation in neural networks?',\n",
       " 'answer': 'To adjust network weights during training',\n",
       " 'explanation': 'Backpropagation is an algorithm that calculates gradients and adjusts network weights to minimize errors.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is gradient descent in the context of neural network training?',\n",
       " 'opt1': 'A method for selecting activation functions',\n",
       " 'opt2': 'An activation function itself',\n",
       " 'opt3': 'A method for initializing network weights',\n",
       " 'opt4': 'An iterative optimization algorithm that minimizes the loss function'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is gradient descent in the context of neural network training?',\n",
       " 'answer': 'An iterative optimization algorithm that minimizes the loss function',\n",
       " 'explanation': 'Gradient descent is an iterative optimization algorithm used to find model parameters that minimize the loss function.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the key difference between a shallow neural network and a deep neural network?',\n",
       " 'opt1': 'Shallow networks use fewer activation functions',\n",
       " 'opt2': 'Deep networks are trained using different algorithms',\n",
       " 'opt3': 'Deep networks use multiple hidden layers',\n",
       " 'opt4': 'Shallow networks are more computationally efficient'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the key difference between a shallow neural network and a deep neural network?',\n",
       " 'answer': 'Deep networks use multiple hidden layers',\n",
       " 'explanation': 'Deep neural networks have multiple hidden layers, while shallow networks have only one or two.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"What is the term 'deep' in 'deep learning' referring to?\",\n",
       " 'opt1': 'The complexity of the algorithms used',\n",
       " 'opt2': 'The amount of training data required',\n",
       " 'opt3': 'The depth (number of hidden layers) in a neural network',\n",
       " 'opt4': 'The high computational cost of training'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"What does the term 'deep' refer to in 'deep learning'?\",\n",
       " 'answer': 'The depth (number of hidden layers) in a neural network',\n",
       " 'explanation': \"'Deep' refers to the number of hidden layers in a neural network, which usually correlates with the complexity of patterns the network can learn.\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the process of training deep neural networks often called?',\n",
       " 'opt1': 'Gradient descent',\n",
       " 'opt2': 'Backpropagation',\n",
       " 'opt3': 'Deep learning',\n",
       " 'opt4': 'Activation function'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the process of training deep neural networks often called?',\n",
       " 'answer': 'Deep learning',\n",
       " 'explanation': 'The process of training deep neural networks is known as deep learning.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What problem do the vanishing and exploding gradient problems primarily affect?',\n",
       " 'opt1': 'Shallow neural networks',\n",
       " 'opt2': 'Recurrent neural networks',\n",
       " 'opt3': 'Convolutional neural networks',\n",
       " 'opt4': 'All types of neural networks equally'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What problem do the vanishing and exploding gradient problems primarily affect?',\n",
       " 'answer': 'Recurrent neural networks',\n",
       " 'explanation': 'The vanishing and exploding gradient problems are particularly prominent in RNNs due to their recurrent nature.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are GRUs (Gated Recurrent Units) and LSTMs (Long Short-Term Memory units)?',\n",
       " 'opt1': 'Types of activation functions',\n",
       " 'opt2': 'Types of regularization techniques',\n",
       " 'opt3': 'Specialized RNN architectures designed to address vanishing/exploding gradients',\n",
       " 'opt4': 'Types of optimization algorithms'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are GRUs (Gated Recurrent Units) and LSTMs (Long Short-Term Memory units)?',\n",
       " 'answer': 'Specialized RNN architectures designed to address vanishing/exploding gradients',\n",
       " 'explanation': 'GRUs and LSTMs are specialized RNN architectures designed to improve the ability to learn long-range dependencies in sequential data.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a significant advantage of using LSTMs over traditional RNNs?',\n",
       " 'opt1': 'LSTMs are computationally more efficient',\n",
       " 'opt2': 'LSTMs are simpler to implement',\n",
       " 'opt3': 'LSTMs have better memory capabilities for long-range dependencies',\n",
       " 'opt4': 'LSTMs are less prone to overfitting'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a significant advantage of using LSTMs over traditional RNNs?',\n",
       " 'answer': 'LSTMs have better memory capabilities for long-range dependencies',\n",
       " 'explanation': 'LSTMs utilize sophisticated mechanisms like gates to better manage information flow, leading to enhanced handling of long-range dependencies compared to traditional RNNs.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a primary way that LSTMs and GRUs mitigate the vanishing gradient problem?',\n",
       " 'opt1': 'By using a different activation function',\n",
       " 'opt2': 'By employing gated mechanisms to control the flow of information',\n",
       " 'opt3': 'By introducing non-linearity in the model',\n",
       " 'opt4': 'By reducing the number of parameters'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a primary way that LSTMs and GRUs mitigate the vanishing gradient problem?',\n",
       " 'answer': 'By employing gated mechanisms to control the flow of information',\n",
       " 'explanation': 'The gates (input, output, forget) in LSTMs and GRUs carefully control the flow of information through the network, preventing gradients from vanishing or exploding during backpropagation.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which of the following is NOT a typical application of LSTMs?',\n",
       " 'opt1': 'Machine translation',\n",
       " 'opt2': 'Image classification',\n",
       " 'opt3': 'Speech recognition',\n",
       " 'opt4': 'Time series forecasting'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which of the following is NOT a typical application of LSTMs?',\n",
       " 'answer': 'Image classification',\n",
       " 'explanation': 'While RNNs can be used for image processing tasks, LSTMs are more commonly applied to sequential data processing problems.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the main states that are transferred from one LSTM block to the next?',\n",
       " 'opt1': 'Input and output states',\n",
       " 'opt2': 'Hidden state and cell state',\n",
       " 'opt3': 'Query and key states',\n",
       " 'opt4': 'Weights and biases'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the main states that are transferred from one LSTM block to the next?',\n",
       " 'answer': 'Hidden state and cell state',\n",
       " 'explanation': 'The hidden state and cell state are the two key internal states that are updated and passed along within an LSTM network.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[15]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
