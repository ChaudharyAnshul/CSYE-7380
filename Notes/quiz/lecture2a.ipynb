{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq = [{\"question\": \"What is a recurrent neural network (RNN) specialized for?\", \"opt1\": \"Processing unstructured data\", \"opt2\": \"Processing sequential data\", \"opt3\": \"Performing parallel computations\", \"opt4\": \"Handling high-dimensional data\"}, {\"question\": \"Why are RNNs called 'recurrent'?\", \"opt1\": \"They use the same weights for every element in a sequence\", \"opt2\": \"They perform the same task for every element in a sequence\", \"opt3\": \"They have a built-in memory mechanism\", \"opt4\": \"All of the above\"}, {\"question\": \"What is the role of the hidden layer in an RNN?\", \"opt1\": \"Receives the input data\", \"opt2\": \"Maintains a hidden state across time steps\", \"opt3\": \"Produces the final output\", \"opt4\": \"Combines inputs from multiple layers\"}, {\"question\": \"In RNNs, what does the 'hidden state' represent?\", \"opt1\": \"The input data at the current time step\", \"opt2\": \"The current output of the network\", \"opt3\": \"A summary of information processed so far\", \"opt4\": \"The weights and biases of the network\"}, {\"question\": \"What type of activation functions are commonly used in RNNs?\", \"opt1\": \"Sigmoid and ReLU\", \"opt2\": \"Tanh and ReLU\", \"opt3\": \"Sigmoid and Tanh\", \"opt4\": \"All of the above\"}, {\"question\": \"What is backpropagation through time (BPTT)?\", \"opt1\": \"A method for training feedforward neural networks\", \"opt2\": \"A method for training recurrent neural networks\", \"opt3\": \"A type of activation function\", \"opt4\": \"A type of regularization technique\"}, {\"question\": \"What are the challenges associated with backpropagation through time (BPTT)?\", \"opt1\": \"Vanishing and exploding gradients\", \"opt2\": \"Computational complexity\", \"opt3\": \"Memory usage\", \"opt4\": \"All of the above\"}, {\"question\": \"What is the primary advantage of using stacked RNNs?\", \"opt1\": \"Increased computational efficiency\", \"opt2\": \"Ability to process larger datasets\", \"opt3\": \"Improved ability to capture complex temporal dependencies\", \"opt4\": \"Reduced risk of overfitting\"}, {\"question\": \"How are RNNs unrolled in a computational graph?\", \"opt1\": \"The network is treated as a single layer\", \"opt2\": \"The network is replicated for each time step\", \"opt3\": \"The network is simplified for faster processing\", \"opt4\": \"The network's architecture is changed\"}, {\"question\": \"What is the purpose of gradient clipping in RNN training?\", \"opt1\": \"To improve the accuracy of the model\", \"opt2\": \"To prevent exploding gradients\", \"opt3\": \"To speed up training\", \"opt4\": \"To reduce overfitting\"}, {\"question\": \"Which of the following is NOT a common optimization algorithm used for RNNs?\", \"opt1\": \"Stochastic Gradient Descent (SGD)\", \"opt2\": \"Adam\", \"opt3\": \"Batch Gradient Descent\", \"opt4\": \"Backpropagation Through Time (BPTT)\"}, {\"question\": \"What does the term 'many-to-one' refer to in the context of RNN applications?\", \"opt1\": \"Multiple inputs, one output\", \"opt2\": \"One input, multiple outputs\", \"opt3\": \"Multiple inputs, multiple outputs\", \"opt4\": \"RNNs only process one input\"}, {\"question\": \"What is a common way to deal with variable-length input sequences in RNNs?\", \"opt1\": \"Using fixed-size inputs\", \"opt2\": \"Truncating long sequences\", \"opt3\": \"Padding shorter sequences\", \"opt4\": \"Both truncating and padding\"}]\n",
    "answers = [{\"question\": \"What is a recurrent neural network (RNN) specialized for?\", \"answer\": \"Processing sequential data\", \"explanation\": \"RNNs are designed to handle sequential data effectively, where the output at each time step is influenced by previous steps.\"}, {\"question\": \"Why are RNNs called 'recurrent'?\", \"answer\": \"All of the above\", \"explanation\": \"The term 'recurrent' highlights the repetition of the same task and weight sharing across time steps, creating an internal 'memory' in the network's processing.\"}, {\"question\": \"What is the role of the hidden layer in an RNN?\", \"answer\": \"Maintains a hidden state across time steps\", \"explanation\": \"The hidden layer captures the context of the sequence, maintaining a hidden state that carries information across time steps.\"}, {\"question\": \"In RNNs, what does the 'hidden state' represent?\", \"answer\": \"A summary of information processed so far\", \"explanation\": \"The hidden state acts as a memory mechanism, summarizing the information from the past inputs influencing the current and future outputs.\"}, {\"question\": \"What type of activation functions are commonly used in RNNs?\", \"answer\": \"All of the above\", \"explanation\": \"Sigmoid, Tanh, and ReLU are all nonlinear activation functions frequently employed in RNNs to add non-linearity to the model's processing\"}, {\"question\": \"What is backpropagation through time (BPTT)?\", \"answer\": \"A method for training recurrent neural networks\", \"explanation\": \"BPTT is a specialized backpropagation algorithm that addresses the temporal dependencies in RNNs by unfolding the network across time steps.\"}, {\"question\": \"What are the challenges associated with backpropagation through time (BPTT)?\", \"answer\": \"All of the above\", \"explanation\": \"Training RNNs with BPTT encounters challenges like vanishing/exploding gradients due to multiplicative nature of gradients across time steps, high computational cost, and high memory usage.\"}, {\"question\": \"What is the primary advantage of using stacked RNNs?\", \"answer\": \"Improved ability to capture complex temporal dependencies\", \"explanation\": \"Stacked RNNs enhance the model's capacity to capture long-range and complex dependencies in sequential data by adding multiple layers.\"}, {\"question\": \"How are RNNs unrolled in a computational graph?\", \"answer\": \"The network is replicated for each time step\", \"explanation\": \"Unrolling an RNN means the network structure is replicated for each time step to illustrate the flow of information through time.\"}, {\"question\": \"What is the purpose of gradient clipping in RNN training?\", \"answer\": \"To prevent exploding gradients\", \"explanation\": \"Gradient clipping limits the magnitude of gradients during backpropagation to prevent them from becoming excessively large and causing instability in the training process.\"}, {\"question\": \"Which of the following is NOT a common optimization algorithm used for RNNs?\", \"answer\": \"Backpropagation Through Time (BPTT)\", \"explanation\": \"Backpropagation Through Time (BPTT) is not an optimization algorithm itself; rather, it's a method of applying backpropagation to recurrent networks with time steps.\"}, {\"question\": \"What does the term 'many-to-one' refer to in the context of RNN applications?\", \"answer\": \"Multiple inputs, one output\", \"explanation\": \"Many-to-one refers to RNN architectures where multiple inputs (a sequence) are processed, producing a single output.\"}, {\"question\": \"What is a common way to deal with variable-length input sequences in RNNs?\", \"answer\": \"Both truncating and padding\", \"explanation\": \"Variable-length sequences are handled either by truncating longer sequences or padding shorter ones to ensure consistent input dimensions to RNNs.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mcq), len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a recurrent neural network (RNN) specialized for?',\n",
       " 'opt1': 'Processing unstructured data',\n",
       " 'opt2': 'Processing sequential data',\n",
       " 'opt3': 'Performing parallel computations',\n",
       " 'opt4': 'Handling high-dimensional data'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a recurrent neural network (RNN) specialized for?',\n",
       " 'answer': 'Processing sequential data',\n",
       " 'explanation': 'RNNs are designed to handle sequential data effectively, where the output at each time step is influenced by previous steps.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Why are RNNs called 'recurrent'?\",\n",
       " 'opt1': 'They use the same weights for every element in a sequence',\n",
       " 'opt2': 'They perform the same task for every element in a sequence',\n",
       " 'opt3': 'They have a built-in memory mechanism',\n",
       " 'opt4': 'All of the above'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"Why are RNNs called 'recurrent'?\",\n",
       " 'answer': 'All of the above',\n",
       " 'explanation': \"The term 'recurrent' highlights the repetition of the same task and weight sharing across time steps, creating an internal 'memory' in the network's processing.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the role of the hidden layer in an RNN?',\n",
       " 'opt1': 'Receives the input data',\n",
       " 'opt2': 'Maintains a hidden state across time steps',\n",
       " 'opt3': 'Produces the final output',\n",
       " 'opt4': 'Combines inputs from multiple layers'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the role of the hidden layer in an RNN?',\n",
       " 'answer': 'Maintains a hidden state across time steps',\n",
       " 'explanation': 'The hidden layer captures the context of the sequence, maintaining a hidden state that carries information across time steps.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"In RNNs, what does the 'hidden state' represent?\",\n",
       " 'opt1': 'The input data at the current time step',\n",
       " 'opt2': 'The current output of the network',\n",
       " 'opt3': 'A summary of information processed so far',\n",
       " 'opt4': 'The weights and biases of the network'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"In the context of deep learning, what does the term 'deep' refer to?\",\n",
       " 'answer': 'The number of hidden layers in the neural network',\n",
       " 'explanation': \"The term 'deep' in deep learning refers to the number of hidden layers in the neural network's architecture.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What type of activation functions are commonly used in RNNs?',\n",
       " 'opt1': 'Sigmoid and ReLU',\n",
       " 'opt2': 'Tanh and ReLU',\n",
       " 'opt3': 'Sigmoid and Tanh',\n",
       " 'opt4': 'All of the above'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What type of activation functions are commonly used in RNNs?',\n",
       " 'answer': 'All of the above',\n",
       " 'explanation': \"Sigmoid, Tanh, and ReLU are all nonlinear activation functions frequently employed in RNNs to add non-linearity to the model's processing\"}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is backpropagation through time (BPTT)?',\n",
       " 'opt1': 'A method for training feedforward neural networks',\n",
       " 'opt2': 'A method for training recurrent neural networks',\n",
       " 'opt3': 'A type of activation function',\n",
       " 'opt4': 'A type of regularization technique'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is backpropagation through time (BPTT)?',\n",
       " 'answer': 'A method for training recurrent neural networks',\n",
       " 'explanation': 'BPTT is a specialized backpropagation algorithm that addresses the temporal dependencies in RNNs by unfolding the network across time steps.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the challenges associated with backpropagation through time (BPTT)?',\n",
       " 'opt1': 'Vanishing and exploding gradients',\n",
       " 'opt2': 'Computational complexity',\n",
       " 'opt3': 'Memory usage',\n",
       " 'opt4': 'All of the above'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the challenges associated with backpropagation through time (BPTT)?',\n",
       " 'answer': 'All of the above',\n",
       " 'explanation': 'Training RNNs with BPTT encounters challenges like vanishing/exploding gradients due to multiplicative nature of gradients across time steps, high computational cost, and high memory usage.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary advantage of using stacked RNNs?',\n",
       " 'opt1': 'Increased computational efficiency',\n",
       " 'opt2': 'Ability to process larger datasets',\n",
       " 'opt3': 'Improved ability to capture complex temporal dependencies',\n",
       " 'opt4': 'Reduced risk of overfitting'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary advantage of using stacked RNNs?',\n",
       " 'answer': 'Improved ability to capture complex temporal dependencies',\n",
       " 'explanation': \"Stacked RNNs enhance the model's capacity to capture long-range and complex dependencies in sequential data by adding multiple layers.\"}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How are RNNs unrolled in a computational graph?',\n",
       " 'opt1': 'The network is treated as a single layer',\n",
       " 'opt2': 'The network is replicated for each time step',\n",
       " 'opt3': 'The network is simplified for faster processing',\n",
       " 'opt4': \"The network's architecture is changed\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How are RNNs unrolled in a computational graph?',\n",
       " 'answer': 'The network is replicated for each time step',\n",
       " 'explanation': 'Unrolling an RNN means the network structure is replicated for each time step to illustrate the flow of information through time.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of gradient clipping in RNN training?',\n",
       " 'opt1': 'To improve the accuracy of the model',\n",
       " 'opt2': 'To prevent exploding gradients',\n",
       " 'opt3': 'To speed up training',\n",
       " 'opt4': 'To reduce overfitting'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of gradient clipping in RNN training?',\n",
       " 'answer': 'To prevent exploding gradients',\n",
       " 'explanation': 'Gradient clipping limits the magnitude of gradients during backpropagation to prevent them from becoming excessively large and causing instability in the training process.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which of the following is NOT a common optimization algorithm used for RNNs?',\n",
       " 'opt1': 'Stochastic Gradient Descent (SGD)',\n",
       " 'opt2': 'Adam',\n",
       " 'opt3': 'Batch Gradient Descent',\n",
       " 'opt4': 'Backpropagation Through Time (BPTT)'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which of the following is NOT a common optimization algorithm used for RNNs?',\n",
       " 'answer': 'Backpropagation Through Time (BPTT)',\n",
       " 'explanation': \"Backpropagation Through Time (BPTT) is not an optimization algorithm itself; rather, it's a method of applying backpropagation to recurrent networks with time steps.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"What does the term 'many-to-one' refer to in the context of RNN applications?\",\n",
       " 'opt1': 'Multiple inputs, one output',\n",
       " 'opt2': 'One input, multiple outputs',\n",
       " 'opt3': 'Multiple inputs, multiple outputs',\n",
       " 'opt4': 'RNNs only process one input'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': \"What does the term 'many-to-one' refer to in the context of RNN applications?\",\n",
       " 'answer': 'Multiple inputs, one output',\n",
       " 'explanation': 'Many-to-one refers to RNN architectures where multiple inputs (a sequence) are processed, producing a single output.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
