{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcq = [{\"question\": \"What is the primary goal of attention mechanisms in neural networks?\", \"opt1\": \"To speed up the computation process\", \"opt2\": \"To reduce the number of parameters\", \"opt3\": \"To focus on relevant parts of the input sequence\", \"opt4\": \"To improve generalization performance\"}, {\"question\": \"In the context of machine translation, what problem does the attention mechanism address?\", \"opt1\": \"The difficulty in handling different languages\", \"opt2\": \"The inability to capture long-range dependencies\", \"opt3\": \"The misalignment of words between source and target languages\", \"opt4\": \"The need for large amounts of training data\"}, {\"question\": \"What is the key difference between soft attention and hard attention?\", \"opt1\": \"Soft attention is differentiable; hard attention is not\", \"opt2\": \"Soft attention assigns weights to all input elements; hard attention selects only one\", \"opt3\": \"Soft attention is computationally more efficient; hard attention is not\", \"opt4\": \"Soft attention requires more training data; hard attention requires less\"}, {\"question\": \"What is self-attention (intra-attention)?\", \"opt1\": \"A type of attention mechanism that focuses on specific parts of the input\", \"opt2\": \"A type of attention mechanism that computes the relevance of each input token to all other tokens in the same sequence\", \"opt3\": \"A type of attention mechanism that combines information from multiple input sequences\", \"opt4\": \"A type of attention mechanism that is used only in sequence-to-sequence models\"}, {\"question\": \"What is the main advantage of using self-attention in transformer models?\", \"opt1\": \"It allows for parallelization\", \"opt2\": \"It captures long-range dependencies\", \"opt3\": \"It improves computational efficiency\", \"opt4\": \"All of the above\"}, {\"question\": \"What is multi-head attention?\", \"opt1\": \"A type of attention mechanism that uses multiple sets of weights to attend to different aspects of the input\", \"opt2\": \"A type of attention mechanism that combines information from multiple input sequences\", \"opt3\": \"A type of attention mechanism that is used only in sequence-to-sequence models\", \"opt4\": \"A type of attention mechanism that focuses on specific parts of the input\"}, {\"question\": \"What is cross-attention (inter-attention)?\", \"opt1\": \"A type of attention mechanism that computes the relevance of each input token to all other tokens in the same sequence\", \"opt2\": \"A type of attention mechanism that combines information from multiple input sequences\", \"opt3\": \"A type of attention mechanism that focuses on specific parts of the input\", \"opt4\": \"A type of attention mechanism that allows one sequence to attend to another sequence\"}, {\"question\": \"In the context of transformer models, what is the purpose of positional encoding?\", \"opt1\": \"To capture semantic relationships between words\", \"opt2\": \"To provide information about the position of tokens in the sequence\", \"opt3\": \"To reduce computational complexity\", \"opt4\": \"To improve generalization performance\"}, {\"question\": \"What is a key challenge associated with using hard attention?\", \"opt1\": \"It is computationally expensive\", \"opt2\": \"It is difficult to train\", \"opt3\": \"It is not differentiable\", \"opt4\": \"All of the above\"}, {\"question\": \"Which of the following is NOT a type of attention mechanism?\", \"opt1\": \"Soft attention\", \"opt2\": \"Hard attention\", \"opt3\": \"Self-attention\", \"opt4\": \"Convolutional attention\"}, {\"question\": \"In self-attention, what are the three matrices used to calculate attention scores?\", \"opt1\": \"Query, Key, Value\", \"opt2\": \"Input, Hidden, Output\", \"opt3\": \"Encoder, Decoder, Attention\", \"opt4\": \"Weight, Bias, Activation\"}, {\"question\": \"What is the purpose of the softmax function in self-attention?\", \"opt1\": \"To introduce non-linearity\", \"opt2\": \"To normalize the attention scores\", \"opt3\": \"To reduce computational complexity\", \"opt4\": \"To improve generalization performance\"}, {\"question\": \"How does the attention mechanism improve the performance of traditional encoder-decoder models?\", \"opt1\": \"By focusing on the most relevant parts of the input sequence\", \"opt2\": \"By capturing long-range dependencies\", \"opt3\": \"By allowing for parallelization\", \"opt4\": \"All of the above\"}]\n",
    "answers =[{\"question\": \"What is the primary goal of attention mechanisms in neural networks?\", \"answer\": \"To focus on relevant parts of the input sequence\", \"explanation\": \"Attention mechanisms help neural networks focus on the most important parts of the input when making predictions, improving accuracy and efficiency.\"}, {\"question\": \"In the context of machine translation, what problem does the attention mechanism address?\", \"answer\": \"The misalignment of words between source and target languages\", \"explanation\": \"Attention mechanisms address the problem of word misalignment by allowing the model to focus on relevant parts of the source sequence when generating each word in the target sequence.\"}, {\"question\": \"What is the key difference between soft attention and hard attention?\", \"answer\": \"Soft attention is differentiable; hard attention is not\", \"explanation\": \"Soft attention is differentiable because it assigns weights to all parts of the input, making it suitable for end-to-end training. Hard attention is non-differentiable because it selects only one part of the input, making it harder to train.\"}, {\"question\": \"What is self-attention (intra-attention)?\", \"answer\": \"A type of attention mechanism that computes the relevance of each input token to all other tokens in the same sequence\", \"explanation\": \"Self-attention allows the model to attend to different parts of the same input sequence, capturing dependencies between elements.\"}, {\"question\": \"What is the main advantage of using self-attention in transformer models?\", \"answer\": \"All of the above\", \"explanation\": \"Self-attention enables parallelization, captures long-range dependencies, and improves computational efficiency.\"}, {\"question\": \"What is multi-head attention?\", \"answer\": \"A type of attention mechanism that uses multiple sets of weights to attend to different aspects of the input\", \"explanation\": \"Multi-head attention allows the model to capture different features or relationships in the input sequence by having multiple sets of weights.\"}, {\"question\": \"What is cross-attention (inter-attention)?\", \"answer\": \"A type of attention mechanism that allows one sequence to attend to another sequence\", \"explanation\": \"Cross-attention allows one sequence (e.g., the decoder in a sequence-to-sequence model) to attend to another sequence (e.g., the encoder), enabling information exchange between them.\"}, {\"question\": \"In the context of transformer models, what is the purpose of positional encoding?\", \"answer\": \"To provide information about the position of tokens in the sequence\", \"explanation\": \"Positional encoding provides the model with information about the order of tokens in the sequence, which is important for understanding sequential data.\"}, {\"question\": \"What is a key challenge associated with using hard attention?\", \"answer\": \"All of the above\", \"explanation\": \"Hard attention is computationally more efficient but harder to train because it is non-differentiable and often requires reinforcement learning.\"}, {\"question\": \"Which of the following is NOT a type of attention mechanism?\", \"answer\": \"Convolutional attention\", \"explanation\": \"Convolutional attention is not a standard type of attention mechanism.\"}, {\"question\": \"In self-attention, what are the three matrices used to calculate attention scores?\", \"answer\": \"Query, Key, Value\", \"explanation\": \"These matrices (Query, Key, Value) are used to compute attention scores that determine the relevance of each input token to other tokens in the sequence.\"}, {\"question\": \"What is the purpose of the softmax function in self-attention?\", \"answer\": \"To normalize the attention scores\", \"explanation\": \"Softmax function converts the attention scores into probabilities, ensuring they sum up to one and represent a probability distribution.\"}, {\"question\": \"How does the attention mechanism improve the performance of traditional encoder-decoder models?\", \"answer\": \"All of the above\", \"explanation\": \"Attention mechanisms enhance encoder-decoder models by focusing on relevant parts of the input, capturing long-range dependencies, and improving parallelization.\"}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mcq), len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary goal of attention mechanisms in neural networks?',\n",
       " 'opt1': 'To speed up the computation process',\n",
       " 'opt2': 'To reduce the number of parameters',\n",
       " 'opt3': 'To focus on relevant parts of the input sequence',\n",
       " 'opt4': 'To improve generalization performance'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the primary goal of attention mechanisms in neural networks?',\n",
       " 'answer': 'To focus on relevant parts of the input sequence',\n",
       " 'explanation': 'Attention mechanisms help neural networks focus on the most important parts of the input when making predictions, improving accuracy and efficiency.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In the context of machine translation, what problem does the attention mechanism address?',\n",
       " 'opt1': 'The difficulty in handling different languages',\n",
       " 'opt2': 'The inability to capture long-range dependencies',\n",
       " 'opt3': 'The misalignment of words between source and target languages',\n",
       " 'opt4': 'The need for large amounts of training data'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In the context of machine translation, what problem does the attention mechanism address?',\n",
       " 'answer': 'The misalignment of words between source and target languages',\n",
       " 'explanation': 'Attention mechanisms address the problem of word misalignment by allowing the model to focus on relevant parts of the source sequence when generating each word in the target sequence.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the key difference between soft attention and hard attention?',\n",
       " 'opt1': 'Soft attention is differentiable; hard attention is not',\n",
       " 'opt2': 'Soft attention assigns weights to all input elements; hard attention selects only one',\n",
       " 'opt3': 'Soft attention is computationally more efficient; hard attention is not',\n",
       " 'opt4': 'Soft attention requires more training data; hard attention requires less'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the key difference between soft attention and hard attention?',\n",
       " 'answer': 'Soft attention is differentiable; hard attention is not',\n",
       " 'explanation': 'Soft attention is differentiable because it assigns weights to all parts of the input, making it suitable for end-to-end training. Hard attention is non-differentiable because it selects only one part of the input, making it harder to train.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is self-attention (intra-attention)?',\n",
       " 'opt1': 'A type of attention mechanism that focuses on specific parts of the input',\n",
       " 'opt2': 'A type of attention mechanism that computes the relevance of each input token to all other tokens in the same sequence',\n",
       " 'opt3': 'A type of attention mechanism that combines information from multiple input sequences',\n",
       " 'opt4': 'A type of attention mechanism that is used only in sequence-to-sequence models'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is self-attention (intra-attention)?',\n",
       " 'answer': 'A type of attention mechanism that computes the relevance of each input token to all other tokens in the same sequence',\n",
       " 'explanation': 'Self-attention allows the model to attend to different parts of the same input sequence, capturing dependencies between elements.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the main advantage of using self-attention in transformer models?',\n",
       " 'opt1': 'It allows for parallelization',\n",
       " 'opt2': 'It captures long-range dependencies',\n",
       " 'opt3': 'It improves computational efficiency',\n",
       " 'opt4': 'All of the above'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the main advantage of using self-attention in transformer models?',\n",
       " 'answer': 'All of the above',\n",
       " 'explanation': 'Self-attention enables parallelization, captures long-range dependencies, and improves computational efficiency.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is multi-head attention?',\n",
       " 'opt1': 'A type of attention mechanism that uses multiple sets of weights to attend to different aspects of the input',\n",
       " 'opt2': 'A type of attention mechanism that combines information from multiple input sequences',\n",
       " 'opt3': 'A type of attention mechanism that is used only in sequence-to-sequence models',\n",
       " 'opt4': 'A type of attention mechanism that focuses on specific parts of the input'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is multi-head attention?',\n",
       " 'answer': 'A type of attention mechanism that uses multiple sets of weights to attend to different aspects of the input',\n",
       " 'explanation': 'Multi-head attention allows the model to capture different features or relationships in the input sequence by having multiple sets of weights.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is cross-attention (inter-attention)?',\n",
       " 'opt1': 'A type of attention mechanism that computes the relevance of each input token to all other tokens in the same sequence',\n",
       " 'opt2': 'A type of attention mechanism that combines information from multiple input sequences',\n",
       " 'opt3': 'A type of attention mechanism that focuses on specific parts of the input',\n",
       " 'opt4': 'A type of attention mechanism that allows one sequence to attend to another sequence'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is cross-attention (inter-attention)?',\n",
       " 'answer': 'A type of attention mechanism that allows one sequence to attend to another sequence',\n",
       " 'explanation': 'Cross-attention allows one sequence (e.g., the decoder in a sequence-to-sequence model) to attend to another sequence (e.g., the encoder), enabling information exchange between them.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In the context of transformer models, what is the purpose of positional encoding?',\n",
       " 'opt1': 'To capture semantic relationships between words',\n",
       " 'opt2': 'To provide information about the position of tokens in the sequence',\n",
       " 'opt3': 'To reduce computational complexity',\n",
       " 'opt4': 'To improve generalization performance'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In the context of transformer models, what is the purpose of positional encoding?',\n",
       " 'answer': 'To provide information about the position of tokens in the sequence',\n",
       " 'explanation': 'Positional encoding provides the model with information about the order of tokens in the sequence, which is important for understanding sequential data.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a key challenge associated with using hard attention?',\n",
       " 'opt1': 'It is computationally expensive',\n",
       " 'opt2': 'It is difficult to train',\n",
       " 'opt3': 'It is not differentiable',\n",
       " 'opt4': 'All of the above'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is a key challenge associated with using hard attention?',\n",
       " 'answer': 'All of the above',\n",
       " 'explanation': 'Hard attention is computationally more efficient but harder to train because it is non-differentiable and often requires reinforcement learning.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which of the following is NOT a type of attention mechanism?',\n",
       " 'opt1': 'Soft attention',\n",
       " 'opt2': 'Hard attention',\n",
       " 'opt3': 'Self-attention',\n",
       " 'opt4': 'Convolutional attention'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which of the following is NOT a type of attention mechanism?',\n",
       " 'answer': 'Convolutional attention',\n",
       " 'explanation': 'Convolutional attention is not a standard type of attention mechanism.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In self-attention, what are the three matrices used to calculate attention scores?',\n",
       " 'opt1': 'Query, Key, Value',\n",
       " 'opt2': 'Input, Hidden, Output',\n",
       " 'opt3': 'Encoder, Decoder, Attention',\n",
       " 'opt4': 'Weight, Bias, Activation'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'In self-attention, what are the three matrices used to calculate attention scores?',\n",
       " 'answer': 'Query, Key, Value',\n",
       " 'explanation': 'These matrices (Query, Key, Value) are used to compute attention scores that determine the relevance of each input token to other tokens in the sequence.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of the softmax function in self-attention?',\n",
       " 'opt1': 'To introduce non-linearity',\n",
       " 'opt2': 'To normalize the attention scores',\n",
       " 'opt3': 'To reduce computational complexity',\n",
       " 'opt4': 'To improve generalization performance'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the purpose of the softmax function in self-attention?',\n",
       " 'answer': 'To normalize the attention scores',\n",
       " 'explanation': 'Softmax function converts the attention scores into probabilities, ensuring they sum up to one and represent a probability distribution.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does the attention mechanism improve the performance of traditional encoder-decoder models?',\n",
       " 'opt1': 'By focusing on the most relevant parts of the input sequence',\n",
       " 'opt2': 'By capturing long-range dependencies',\n",
       " 'opt3': 'By allowing for parallelization',\n",
       " 'opt4': 'All of the above'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcq[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does the attention mechanism improve the performance of traditional encoder-decoder models?',\n",
       " 'answer': 'All of the above',\n",
       " 'explanation': 'Attention mechanisms enhance encoder-decoder models by focusing on relevant parts of the input, capturing long-range dependencies, and improving parallelization.'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[12]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
