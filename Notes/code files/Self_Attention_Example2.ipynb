{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85648aa5",
   "metadata": {},
   "source": [
    "# Lecture 4 Self-Attention\n",
    "\n",
    "#### 2 Self-Attention Using PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e403426",
   "metadata": {},
   "source": [
    "Leveraging PyTorch, this example implements self-attention as a module, showcasing how it can be integrated into neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f29ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18b7e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, heads = 1):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        assert embed_dim % heads == 0, \"Embedding dimension must be divisible by number of heads.\"\n",
    "        self.embed_dim = embed_dim\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_dim // heads\n",
    "\n",
    "        # Define linear layers for queries, keys, and values\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        # Output linear layer\n",
    "        self.out = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "\n",
    "        # Linear projections\n",
    "        Q = self.query(x).view(batch_size, seq_length, self.heads, self.head_dim)\n",
    "        K = self.key(x).view(batch_size, seq_length, self.heads, self.head_dim)\n",
    "        V = self.value(x).view(batch_size, seq_length, self.heads, self.head_dim)\n",
    "\n",
    "        # Transpose for attention calculation\n",
    "        Q = Q.transpose(1, 2)  # (batch, heads, seq_length, head_dim)\n",
    "        K = K.transpose(1, 2)\n",
    "        V = V.transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.head_dim, dtype=torch.float32))\n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        out = torch.matmul(attention, V)  # (batch, heads, seq_length, head_dim)\n",
    "\n",
    "        # Concatenate heads\n",
    "        out = out.transpose(1, 2).contiguous().view(batch_size, seq_length, embed_dim)\n",
    "\n",
    "        # Final linear layer\n",
    "        out = self.out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a5ef4",
   "metadata": {},
   "source": [
    "#### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe620d92",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences: [['cash', 'is', 'the', 'king'], ['do', 'not', 'time', 'the', 'market']]\n",
      "Vocabulary: {'cash': 1, 'is': 2, 'the': 3, 'king': 4, 'do': 5, 'not': 6, 'time': 7, 'market': 8}\n",
      "Encoded Sentences: [[1, 2, 3, 4], [5, 6, 7, 3, 8]]\n",
      "Padded Sentences: [[1, 2, 3, 4, 0], [5, 6, 7, 3, 8]]\n",
      "Max Length: 5\n",
      "Encoded Tensor:\n",
      "tensor([[1, 2, 3, 4, 0],\n",
      "        [5, 6, 7, 3, 8]])\n",
      "Tensor Shape: torch.Size([2, 5])\n",
      "One-Hot Encoded Tensor:\n",
      "tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1.]]])\n",
      "One-Hot Tensor Shape: torch.Size([2, 5, 9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1. Define your sentences\n",
    "sentences = [ \n",
    "    \"Cash is the king\",\n",
    "    \"Do not time the market\",\n",
    "]\n",
    "\n",
    "# 2. Tokenize the sentences\n",
    "# Convert to lowercase and split by spaces\n",
    "tokenized_sentences = [sentence.lower().split() for sentence in sentences]\n",
    "print(\"Tokenized Sentences:\", tokenized_sentences)\n",
    "\n",
    "# 3. Build a vocabulary\n",
    "# Assign a unique index to each unique token\n",
    "# Reserve 0 for padding\n",
    "vocab = {}\n",
    "current_index = 1  # Start indexing from 1\n",
    "\n",
    "for sentence in tokenized_sentences:\n",
    "    for token in sentence:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = current_index\n",
    "            current_index += 1\n",
    "\n",
    "print(\"Vocabulary:\", vocab)\n",
    "\n",
    "# Optionally, add an <UNK> token for unknown words\n",
    "# vocab['<UNK>'] = current_index\n",
    "# current_index += 1\n",
    "\n",
    "# 4. Encode the sentences\n",
    "# Replace each token with its corresponding index\n",
    "encoded_sentences = []\n",
    "for sentence in tokenized_sentences:\n",
    "    encoded = [vocab.get(token, 0) for token in sentence]  # Use 0 if token not found\n",
    "    encoded_sentences.append(encoded)\n",
    "\n",
    "print(\"Encoded Sentences:\", encoded_sentences)\n",
    "\n",
    "# 5. Pad the sequences\n",
    "# Find the length of the longest sentence\n",
    "max_length = max(len(sentence) for sentence in encoded_sentences)\n",
    "\n",
    "# Pad shorter sentences with 0 (padding index)\n",
    "padded_sentences = [\n",
    "    sentence + [0] * (max_length - len(sentence)) for sentence in encoded_sentences\n",
    "]\n",
    "\n",
    "print(\"Padded Sentences:\", padded_sentences)\n",
    "\n",
    "# Verify max_length is 5\n",
    "print(\"Max Length:\", max_length)\n",
    "\n",
    "# 6. Convert to PyTorch tensor\n",
    "encoded_tensor = torch.tensor(padded_sentences, dtype=torch.long)\n",
    "print(\"Encoded Tensor:\")\n",
    "print(encoded_tensor)\n",
    "print(\"Tensor Shape:\", encoded_tensor.shape)  # Should be (2, 5)\n",
    "\n",
    "# 7. One-Hot Encode the tensor\n",
    "# Number of classes is the size of the vocabulary + 1 for padding (if not already included)\n",
    "num_classes = len(vocab) + 1  # +1 for padding index 0\n",
    "\n",
    "# Use F.one_hot to convert to one-hot vectors\n",
    "# F.one_hot expects the class indices to be in the last dimension\n",
    "one_hot_tensor = F.one_hot(encoded_tensor, num_classes=num_classes).float()\n",
    "\n",
    "print(\"One-Hot Encoded Tensor:\")\n",
    "print(one_hot_tensor)\n",
    "print(\"One-Hot Tensor Shape:\", one_hot_tensor.shape)  # Should be (2, 5, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c7f41",
   "metadata": {},
   "source": [
    "**Explanation of Each Step:**\n",
    "- Tokenization:\n",
    "    - Converts each sentence to lowercase for consistency.\n",
    "    - Splits sentences into lists of tokens (words).\n",
    "- Vocabulary Building:\n",
    "    - Iterates through all tokens and assigns a unique integer to each unique token.\n",
    "    - Starts indexing from 1 to reserve 0 for padding purposes.\n",
    "- Encoding:\n",
    "    - Transforms each token in the sentences to its corresponding integer index based on the vocabulary.\n",
    "    - Tokens not found in the vocabulary are replaced with 0 (you can use an UNK token for unknown words if desired).\n",
    "- Padding:\n",
    "    - Determines the length of the longest sentence to ensure all sequences are of equal length.\n",
    "    - Pads shorter sentences with 0 (the padding index).\n",
    "- One-Hot Encoding:\n",
    "    - Converts the indexed tokens into one-hot vectors.\n",
    "    - The torch.nn.functional.one_hot function is used for this purpose.\n",
    "- The initial one-hot encoding includes the padding class, resulting in a tensor of shape (2, 5, 9). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d4d6df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-Attention Output:\n",
      " tensor([[[ 0.2029,  0.1996, -0.2246, -0.0150, -0.4431, -0.0509, -0.0603,\n",
      "           0.3259, -0.1087],\n",
      "         [ 0.2048,  0.1972, -0.2192, -0.0119, -0.4437, -0.0512, -0.0606,\n",
      "           0.3270, -0.1078],\n",
      "         [ 0.2015,  0.1982, -0.2274, -0.0164, -0.4435, -0.0497, -0.0574,\n",
      "           0.3256, -0.1110],\n",
      "         [ 0.2043,  0.1970, -0.2212, -0.0132, -0.4424, -0.0496, -0.0596,\n",
      "           0.3257, -0.1095],\n",
      "         [ 0.2038,  0.1969, -0.2227, -0.0141, -0.4417, -0.0486, -0.0587,\n",
      "           0.3251, -0.1106]],\n",
      "\n",
      "        [[ 0.1540,  0.1029, -0.2362, -0.0197, -0.4905, -0.1299, -0.1160,\n",
      "           0.2796, -0.1280],\n",
      "         [ 0.1545,  0.1044, -0.2347, -0.0203, -0.4920, -0.1325, -0.1166,\n",
      "           0.2800, -0.1266],\n",
      "         [ 0.1523,  0.1078, -0.2344, -0.0217, -0.4923, -0.1314, -0.1166,\n",
      "           0.2803, -0.1244],\n",
      "         [ 0.1548,  0.1040, -0.2393, -0.0226, -0.4937, -0.1304, -0.1140,\n",
      "           0.2813, -0.1292],\n",
      "         [ 0.1540,  0.1053, -0.2335, -0.0207, -0.4929, -0.1325, -0.1171,\n",
      "           0.2804, -0.1255]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "self_attention = SelfAttention(embed_dim = 9, heads = 1)\n",
    "output = self_attention(one_hot_tensor)\n",
    "print(\"Self-Attention Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5568aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
