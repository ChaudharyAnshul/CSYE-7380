{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b5dfe5",
   "metadata": {},
   "source": [
    "# LSTM Example 1: A Toy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8abdbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def sigmoid(x): \n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "#Prepare and download stock price \n",
    "start_date = datetime(2022,1,1)\n",
    "end_date = datetime(2024,1,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce0dc1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29722938291223905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stock = yf.download('AAPL',start_date ,end_date)\n",
    "stock_price = pd.DataFrame(stock['Adj Close'])\n",
    "stock_volume = pd.DataFrame(stock['Volume'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "price_scaled = pd.Series(scaler.fit_transform(stock_price).squeeze(),index=stock.index)\n",
    "price_scaled.describe()\n",
    "adjClose = price_scaled.values.tolist()\n",
    "volume_scaled = pd.Series(scaler.fit_transform(stock_volume).squeeze(), index=stock.index)\n",
    "volume_scaled.describe()\n",
    "tradeVolume = volume_scaled.values.tolist()\n",
    "\n",
    "#Configurate \n",
    "input_size = 2  # M x 1\n",
    "hidden_size = 3 # K x 1\n",
    "output_size = 1 # N x 1\n",
    "hidden_state_prev = np.zeros((hidden_size,1))  \n",
    "final_memory_prev = np.zeros((hidden_size,1))  \n",
    "targets = adjClose[1:] # we use data from 0 : T-1 to predict adjusted close for 1 : T\n",
    "S = len(targets)\n",
    "\n",
    "#Initialize weights and biases (parameters)\n",
    "# Input Gate\n",
    "input_weights_U_i = np.random.randn(hidden_size, input_size) \n",
    "hidden_weights_W_i = np.random.randn(hidden_size, hidden_size) \n",
    "hidden_bias_i = np.zeros((hidden_size, 1)) \n",
    "\n",
    "# Forget Gate\n",
    "input_weights_U_f = np.random.randn(hidden_size, input_size)\n",
    "hidden_weights_W_f  = np.random.randn(hidden_size, hidden_size) \n",
    "hidden_bias_f = np.zeros((hidden_size, 1)) \n",
    "\n",
    "# Output Gate\n",
    "input_weights_U_o = np.random.randn(output_size, input_size) \n",
    "hidden_weights_W_o = np.random.randn(output_size, hidden_size) \n",
    "hidden_bias_o = np.zeros((output_size, 1)) \n",
    "\n",
    "# New Memory\n",
    "input_weights_U_new = np.random.randn(hidden_size, input_size) \n",
    "hidden_weights_W_new = np.random.randn(hidden_size, hidden_size) \n",
    "\n",
    "#Forward pass: choose dictionaries as data type with keys to be the timestamp. \n",
    "xs, hidden_states, outputs = {}, {}, {}\n",
    "input_gate, forget_gate, new_memory, final_memory = {}, {}, {}, {}\n",
    "loss = 0\n",
    "hidden_states[-1] = np.copy(hidden_state_prev)\n",
    "final_memory[-1] = np.copy(final_memory_prev)\n",
    "for t in range(0, S): \n",
    "    # stacking inputs into M x 1 vector (M features)\n",
    "    xs[t] = np.zeros((input_size,1))  # 2 x 1\n",
    "    xs[t][0] = adjClose[t] # the 1st element in the input is adjClose \n",
    "    xs[t][1] = tradeVolume[t] # the 2nd element in the input is tradeVolume \n",
    "    # Compute input gate K x 1\n",
    "    input_gate[t] = sigmoid(input_weights_U_i @ xs[t] \n",
    "                               + hidden_weights_W_i @ hidden_states[t-1] \n",
    "                               + hidden_bias_i)\n",
    "    # Compute forget gate K x 1\n",
    "    forget_gate[t] = sigmoid(input_weights_U_f @ xs[t] \n",
    "                               + hidden_weights_W_f @ hidden_states[t-1] \n",
    "                               + hidden_bias_f)\n",
    "    # Compute output gate N x 1\n",
    "    outputs[t] = sigmoid(input_weights_U_o @ xs[t] \n",
    "                               + hidden_weights_W_o @ hidden_states[t-1] \n",
    "                               + hidden_bias_o)  \n",
    "    # Generate new memory K x 1\n",
    "    new_memory[t] = np.tanh(input_weights_U_new @ xs[t] \n",
    "                               + hidden_weights_W_new @ hidden_states[t-1] )\n",
    "    # Generate final memory K x 1 \n",
    "    # np.ravel is to change a 2-dimensional array or a multi-dimensional array into a contiguous flattened array. \n",
    "    final_memory[t] = np.tanh(np.ravel(forget_gate[t])*np.ravel(final_memory[t-1]) \n",
    "                               +  np.ravel(input_gate[t])*np.ravel(new_memory[t]))\n",
    "    # Update hidden state K x 1\n",
    "    hidden_states_array =  np.ravel(outputs[t])*final_memory[t]\n",
    "    hidden_states[t] =  hidden_states_array.reshape(-1,1)\n",
    "    # Compute mean-squared error loss\n",
    "    # - choose RMSE as loss, probablities are no longer in need.\n",
    "    # - outputs[t] is numpy array, e.g. array([[0.5001818]]), indexing [0][0] is to take the number values.\n",
    "    loss += (targets[t] -  outputs[t][0][0])**2\n",
    "    \n",
    "loss_rmse = np.sqrt(loss/S)\n",
    "print(loss_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d8caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
